There are a few ways in which we look to expand upon the aforementioned algorithms:

\begin{itemize}
\item Loosening the requirement of linear separability for SVMs by incorporating kernels
\item Giving different weights to unigrams, bigrams, and trigrams in Naive Bayes
\item Adjusting weights (importance) of certain words in Naive Bayes, e.g. giving additional weight to emoticons and hashtags
\item Full implementation of MRF, performed for several different time windows, more granular sets of locations (e.g. cities instead of states), and with different sets of edge matrices $T$
\item Modeling dependencies between sentiment and weather kind (e.g. if sentiment is negative, then it's more likely to be snowy than sunny)
\end{itemize}
