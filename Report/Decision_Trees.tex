	One discriminative algorithm we used to classify the tweets is decision trees. From the homework set, we saw that decision trees could be useful for classifying texts into different genres. Therefore, we used the TDIT algorithm along with information gain to the build decision trees for classifying the ``when'', ``sentiment'' and ``kind'' labels of tweets. Since a tweet can have multiple ``kind'' labels, we constructed a tree for each of the fifteen labels indicating either ``positive'' or ``negative.'' Then the vector of ``kind'' labels can be generated from the output of each of the fifteen trees.

	The feature vectors used to represent the tweets were the bag of ``important'' words constructed from the NaÃ¯ve Bayes conditional probabilities. Thus, each attribute represented a word count. Then the splitting criteria used was either $>0$ or $>1$ depending on which gave more information gain. In order to prevent overfitting early stopping was used. Lastly, cross validation was used to determine the optimal tree depth from a range of 2 to 60. 