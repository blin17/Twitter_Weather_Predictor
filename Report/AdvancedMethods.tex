	Although the words within a tweet can be strong indicators of the weather conditions surrounding a tweet, it is also helpful to know the location and time of the tweet. For example, if the tweet is made in Boston in December, there is likely to be snow. The traditional machine learning methods presented thus far don't leverage this sort of spatial and temporal data to make better-informed decisions. To this end, Markov Random Fields are particularly helpful.

	The data used for MRF was described in the ``Data manipulation'' section. With each tweet in this data set is information on the city from which the tweet's user came from\footnote{It could be the case that a user from city A is actually making a tweet from city B and commenting on city B's weather, but the hope is that this isn't too frequent.}, and to simplify our model we mapped each city to its state, just to make the locations less granular. 

	Now, the goal for us here is to try to use location/time data to extract the kind of weather condition from a tweet. The general idea behind Markov Random Fields is to model dependencies between variables and gain insight from these dependencies when making predictions. To use this concept, we assume that close-together regions experience similar weather, and we focus on just a small window of time (half a day) to avoid vast variations in weather within a region. 

	The graphical model is as follows. We have a graph with nodes corresponding to states within the United States. There is an undirected edge between nodes if the corresponding states share a border. For each edge $e=(u,v)$ we assign a $15 \times 15$ table $T_e$, where the rows and columns are the 15 different weather kind categories -- the rows correspond to state $u$ and the columns correspond to state $v$ (without loss of generality), and the value in table entry $T_e[i,j]$ is relatively large if there's a high likelihood of state $u$ experiencing weather $i$ when state $v$ experiences weather $j$, but relatively small if the likelihood of this is low. Given our assumption that neighboring states have similar weather, this means that values along the main diagonal will be larger than values off the main diagonal.

	The goal is to determine the kind of weather for each node (i.e. each window of time for each region), and then label each tweet from that location/time with the kind of weather for the corresponding node. So the question is, how does one label a node? Consider a node $u$ with, say, four neighbors $n_1, n_2, n_3, n_4$ which have already have labels $l_1, l_2, l_3,l_4$ fixed. We also already have a training set of tweets from the location/time corresponding to node $u$, and we collect the words from all these tweets into a bag of words; for each word, we have a length-15 vector $\bar{w}$ of probabilties $P(y|w)$, i.e. the probability that the kind of weather is $y$ (for all 15 kinds of weather) given that a tweet has word $w$. 

	Then, to label a node, we do the following. For each neighbor $n_i$ there is an edge matrix $T_{(n_i,u)}$ as defined earlier, and since the label of $n_i$ is fixed, we have a row vector (could be a column vector, but I'll call it a row without loss of generality) corresponding to the likelihood of $u$ having a certain label given that $n_i$ has label $l_i$. Let's normalize these vectors so that the entries are probabilities. 

	Additionally, for each tweet we're classifying from $u$'s location/time, we have a vector of probabilities that the tweet belongs to each kind of weather (from Naive Bayes). Multipliying these tweet vectors and neighbor vectors pointwise, and then normalizing, we produce a final vector $v$ of probabilities that node $u$ belongs to each particular kind of weather -- these probabilties therefore take into account the training data \emph{and} the location/time, as desired. Using this vector of probabilities, we draw at random a kind of weather to label $u$ with (the random drawing is done in a way so that the probability of drawing the $i^{th}$ kind is $v_i$).

	Repeating this process for each node gives us labels for each node. This begs the question -- how do we come up with an initial labelling of nodes? Certainly, some initial labelling is necessary in order to assume that the neighbors are pre-labelled. To this end, we require the method Gibbs Sampling. We assign each node an initial label at random (or not-so-random, e.g. an educated guess given prior results from Naive Bayes), and then perform our labelling as described. After several (perhaps hundreds) iterations of labelling each node, we'd converge to a label likely to be correct. At this point, we get a label $l$ for each location/time node $u$ by taking the mode of all labels produced for $u$ throughout the Gibbs Sampling, and we assign label $l$ to each tweet from the location/time corresponding to $u$. 

	One slight shortcoming here is that we assign each tweet one kind of weather, when a location can experience multiple kinds of weather at one (e.g. cloudiness and rain). A solution here is to look at the final probability vector for a node and label the node with the label of max probability plus all labels with probablilities greater than or equal to some threshold (e.g. 0.7).